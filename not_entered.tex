\subsubsection{Эталонный тест производительности}

Рассмотрим основные подходы к оценке точности работы алгоритма. 

Одной из широко используемых метрик оценки точности отслеживания является ошибка определения алгоритмом местоположения центра отслеживаемого объекта, которая определяется как среднее евклидово расстояние между центральными точками отслеживаемых целей и обозначенными вручную истинными значениями объекта. Однако, если какая-либо модель потеряет цель - выходное местоположение (выводимая траектория движения) может быть случайным, а значит дана характеристика может не правильно измерять эффективность алгоритма.По этому в данном случае, она показывает процент кадров, чье предполагаемое местоположение находится в пределах заданного порогового значения. Оценка для порога по умолчанию $= 20$ пикселям.

Вторая рассматриваемая метрика оценки - это на сколько точно ограничивающая рамка покрывает движущийся объект.
Так как для каждого примера есть координаты задающие рамку $r_{t}$ в момент времени $t$ и $r_{a}$ - действительное расположение объекта, понятно, что $S$ \eqref{S} определенная следующим образом:

\begin{equation} \label{S}
    S = \dfrac{|r_{a} \cap r_{t}|}{|r_{a} \cup r_{t}|}
\end{equation}

где $| \cdot |$ - это количество пикселей. 
Чтобы измерить производительность на последовательности кадров, мы подсчитываем количество успешных кадров, чье перекрытие $S$ превышает заданный порог.Введем понятие  графика успеха, который показывает соотношение успешных кадров при пороговых значениях, изменяющихся от 0 до 1. Использование одного значения показателя успешности при конкретном пороговом значении (например, до $0,5$) для оценки алгоритма может быть не точен. Вместо этого, мы используем область под кривой (AUC) каждого графика успеха для разделения межу собой алгоритмов отслеживания относительно этой характеристики.

Оценка надежности модели - это то, как именно проверяются описанные выше характеристики для моделей. Например, в статье [3] оценка происходит тремя способами:

\begin{itemize}[leftmargin=0em, itemindent=2.5 em,itemsep=1.5 pt,parsep=1.5 pt]

    \item[--] Однократная оценка (ORE). Для нее на протяжении всей видео - последовательности, начиная с позиции истинного положения в первом кадре, подсчитывается точность центра и точность ограничивающей рамки для каждого из моделей. Для OPE каждая модель тестируется более чем на $29 000$ кадров. 
    
    \item[--] Оценка временной устойчивости (TRE). Так как конкретная модель может быть чувствительна к инициализации, и его производительность с другой инициализацией, то есть в другом начальном кадре может стать намного хуже или лучше, TRE - это запуск моделей с возмущенными начальными данными во времени (то есть, начиная с разных кадров). Для TRE каждая последовательность видео делится на 20 сегментов, и, таким образом, каждая модель выполняется примерно на 310 000 кадров.
    
    \item[--] Оценка пространственной устойчивости (SRE). Аналогична TRE, только возмущается стартовая позиция ограничивающей рамки объекта. Для SRE каждая модель оценивается 12 раз для каждой последовательности видео, где генерируется более 350 000 результатов ограничивающей рамки. 
    
\end{itemize}

На базе каждой из оценок строятся соответствующие графики, для сравнения между собой моделей отслеживания.
